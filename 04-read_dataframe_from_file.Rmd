# Working with files

<script src="js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

<script src="js/dcl.js"></script>
```{r include=FALSE}
tutorial::go_interactive(greedy=TRUE)
knitr::opts_chunk$set(echo = TRUE,error=TRUE)
```

## .XLSX, XLS files
### Reading a file to a dataframe 

This chapter explains how to read a file to a data frame using the `readxl` library. The `readxl` package can be installed from the console by `install.packages("readxl")` command.

Lets begin by importing the library
```{r echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
# Import the library
library(readxl)
```

The `readxl` library can read .xlsx, xls files to a data frame. For this case, Human genome excel file is read. 
```{r}
# Import the library
library(readxl)

# Read the excel file
hg = read_excel("data/Human_genome.xlsx")
```

View the data set 
```{r}
# Import the library
library(readxl)

# Read the excel file
hg = read_excel("data/Human_genome.xlsx")

# View the dataset
str(hg)
```

In R, `head()` and `tail()` are functions used to view the first few rows or the last few rows of a data frame respectively. These functions are particularly useful for quickly inspecting the structure and content of a dataset.

Here's how you can use them for this case;
```{r}
# Import the library
library(readxl)

# Read the excel file
hg = read_excel("data/Human_genome.xlsx")

# Display the first 6 records of the data set
head(hg)
```

The `head()` function displays the first few rows of a data frame or a vector. By default, it shows the first 6 rows, but you can specify the number of rows to display using the `n` argument.
```{r}
# Import the library
library(readxl)

# Read the excel file
hg = read_excel("data/Human_genome.xlsx")

# Specify the number of the first rows you want to view
head(hg, n=10)
```
The tail argument can be used as;
```{r}
# Import the library
library(readxl)

# Read the excel file
hg = read_excel("data/Human_genome.xlsx")

# View the last 6 rows of the dataset. 
tail(hg)
```
to show the last 6 records while specifying `n` value will show the specified number of rows. 

R identifies this type of data as table or data frame. 
```{r}
class(hg)
```

`str()` is used to find the nature of data such as column data types, number of rows and columns, column names , and first records in the dataframe
```{r}
str(hg)
```

`is.na()` is used to check if there is null/blank values in the dataset. If there is it returns TRUE in place of the null point while it return FALSE in place of the value. 
```{r}
sum(is.na(hg))
```
The "hg" data frame has no null values. 

Lets dive into biology to solve some of the questions about genetics 

**Q1. Calculate the gene densityfor each chromosome**

The gene density is calculated in terms of genes per megabase
```{r}
base_Mb = hg$Base_Pairs/1000000
base_Mb
```

To make the values more clear, the results can be rounded off to two decimal place. 
```{r}
rbase_Mb=round(base_Mb, digits = 2)
rbase_Mb
```

**Q2. Calculate number of genes per megabase per chromosomes**

The protein coding genes are divided to the gene density. 
```{r}
genes_per_megabase = round(hg$Protein_Coding_genes/base_Mb, digits = 2)
genes_per_megabase
```

Lets create a new column to the dataframe to the dataset 
```{r}
hg["genes_per_Mb"]=genes_per_megabase
str(hg)
```

### Write a new table to a file locally
The `write.table()` function is used to write table to file on a local machine. The file is saved by deault to the working directory unless the path is specified. 
```{r}
write.table(hg, 
            file="data/hg_modified", 
            quote=FALSE, 
            sep='\t', 
            row.names=FALSE, 
            col.names=TRUE)
```

This file will be saved by default on the working directory unless the file path is changed. 

Checking if the new file is saved. 
```
file.show("data/hg_modified")
```
## .CSV files 
CSV stands for "Comma Separated Values". This is a plain text file that contains data in a tabular format for example the data below that represents athletes' statistics. 
```
Name, Age, Weight
Salman, 30, 75
Pragya, 35, 72
Vidyat, 25, 68
```

Each line in a CSV file represents a row while each field in a row is separated by a comma ",". These files are often used in data manipulations since they are lightweight, simple and widely supported. In this course we shall briefly go through two csv files and do brief analyses. 

### Titanic dataset
The titanic data is a famous data set in data analysis. It contains information about passengers that boarded the ship Titan(not actual true) including their age, ticket class, fare and others. 

#### Reading the csv file

The `read.csv()` function is used to read a csv file to a data frame.
```{r}
# Read data from a CSV file into a data frame
titanic_df = read.csv("data/titanic_dataset.csv")
```

#### Data Assessment

- Structure of the data set
```{r}
str(titanic_df)
```

- Show the first 6 records of the data set.
```{r}
head(titanic_df)
```

- Count the null values in the data
```{r}
sum(is.na(titanic_df))
```

The are 87 fields in the data that are null(empty)

- Calculate the descriptive statistics
```{r}
summary(titanic_df)
```

#### Data Analysis 
The answers to the two questions will give a brief understanding of titanic passengers.

- **What is the survival rate by gender?**
```{r}
# Survival rate by gender
table(titanic_df$Sex, titanic_df$Survived)
```

From the table above, all males drowned but all females survived. 

- **What is the survival rate by ticket class?**
```{r}
# Survival rate by ticket class
table(titanic_df$Pclass, titanic_df$Survived)
```

Most passengers from ticket class 0 survived. 

<span style="color: green;">*Activity*</span>


### IBM Employee Attrition data 
This is a common data set used for HR analytics. It contains information about all IBM employees, who are still in the company and the ones who left. Analyzing this attrition data set will provide meaningful insights on employees' behavior and their engagement. HR can also find employee retention techniques with organizations. In this course section, we will briefly go through basic analysis after assessing the data. 

#### Reading the csv file 
```{r}
attrition_df = read.csv("data/HR-Employee-Attrition.csv")
```

#### Data Assessment
- Structure of the data 
```{r}
str(attrition_df)
```

Most columns have character and integer values. 

- Shape of the data set 
```{r}
dim(attrition_df)
```

There are 1470 rows and 35 variables in the data set. Lets now show the first few rows of the data to get the idea of how the data looks like.
```{r}
head(attrition_df)
```

It is also important when analyzing data to find the existence of null fields and duplicated records. 

- Are there any null values?
```{r}
sum(is.na(attrition_df))
```

The data is complete with no null values. 

- Are there any duplicated rows?
```{r}
sum(duplicated(attrition_df))
```

Also, all the rows are unique and there is no duplicated row in the data. 

#### Data Analysis
The following questions will enable us to get a brief overview of the company;

- **What are the unique departments in the company?**
```{r}
unique(attrition_df$Department)
```

There are three distinct departments in the company data; Human Resources, Sales, and Research & Development. 

- **Is there a difference in attrition rates between genders?**
```{r}
# Table of attrition by gender
table(attrition_df$Gender, attrition_df$Attrition)
```

From the table, we can see the number of males and females who have left the company (Attrition=Yes) and those who are still employed (Attrition=No)

- **What is the attrition rate among employees in different job roles?**
```{r}
# Table of attrition by job role
table(attrition_df$JobRole, attrition_df$Attrition)
```

From the table above there is a high attrition rate among Laboratory technicians(62) and Sales Executives(57) while lowest attrition rate among Research directors(2) and Managers(5). 

- **Does age impact attrition rate?**

To find a clear answer to this, the ages will be summarized into different groups and create a table comparing the attrition and retention rates among different age groups. 
```{r}
# Table of attrition by age group
attrition_df$AgeGroup <- cut(attrition_df$Age, breaks = c(0, 30, 40, 50, 60, 70), labels = c("0-30", "31-40", "41-50", "51-60", "61-70"))

# Create a table
table(attrition_df$AgeGroup, attrition_df$Attrition)
```

Young employees below 30 years tend to leave the company than elder employees of above 40 years who are mostly retained by the company. 

<span style="color: green;">**Activity**</span>

data link: https://raw.githubusercontent.com/insaid2018/Term-1/master/Data/Projects/car_sales.csv

In this activity we shall be reading a csv file directly from an online repository and provide the answers to the questions below;

  i. Read the csv file to a data frame `car_sales`. **Hint**:*Use the data link above as a filepath*
  ii. What are the columns in the data frame? Use `colnames()` function.
  iii. How many records and columns are there in the data frame?
  iv. Print the last five records in the `car_sales` data frame
  
```{r ex="activity-4b", type="sample-code"}
# i. Read the csv file to a data frame `car_sales`. 
# CODE HERE 

# ii. What are the columns in the data frame? Use `colnames()` function.
# CODE HERE 

# iii. How many records and columns are there in the data frame?
# CODE HERE 

# iv. Print the last five records in the `car_sales` data frame
# CODE HERE 
```

```{r ex="activity-4b", type="solution"}
# i. Read the csv file to a data frame `car_sales`. 
data_link = "https://raw.githubusercontent.com/insaid2018/Term-1/master/Data/Projects/car_sales.csv"
car_sales = read.csv(data_link)

# ii. What are the columns in the data frame? 
colnames(car_sales)

# iii. How many records and columns are there in the data frame?
dim(car_sales)

# iv. Print the last five records in the `car_sales` data frame
tail(car_sales, 5)
```

## CODE CHALLENGE
excel data - https://www.kaggle.com/datasets/suruchiarora/yahoo-finance-dataset-2018-2023

csv data - https://www.kaggle.com/datasets/prasad22/vehicle-population-statistics

1. In this question you will be required to download kaggle data set, the Yahoo data 2018-2023 from [here](https://www.kaggle.com/datasets/suruchiarora/yahoo-finance-dataset-2018-2023). Follow the instructions below to work on the data set. 
    
    a. Install and load the `readxl` library. 
    b. Read the excel file to a data frame using `read_excel()` function. Store the data frame in a variable, `yahoo_data`. 
    c. Use `str()` command to get a glimpse of the dataset. 
    d. Show the first 4 records and the last 10 records of the `yahoo_data` using the `head()` and `tail()` command respectively. 
    e. Calculate the total null values in the `yahoo_data` using the `sum()` along with `is.na()` functions. 
    f. Find the total duplicated observations in the `yahoo_data` with `sum()` and `duplicated()` commands. 
2. In this second part of the challenge, you will be required to download a kaggle data set - the vehicle population statistics csv file from [here](https://www.kaggle.com/datasets/prasad22/vehicle-population-statistics). You will use the data set to answer the following questions. 

    a. Read the data set to a data frame using the `read.csv` inbuilt function. Store the data frame in a variable `vehicle_data`. 
    b. Display the first 6 rows and the last 3 rows using the `head()` and `tail()` functions respectively. 
    c. Show the first 10 observations in the `"Scooters"` column. 
    d. What are the number of Jeeps per Region. Use table functions. **Hint**:*Refer from "What is the survival rate by gender?" in the content above*
    e. What are the distinct categories in the `vehicle_data`.